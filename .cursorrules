# Cursor IDE Rules

## System Configuration

architecture: {
    platform: "arm64-darwin",              # MacBook Air M3 specific
    memory_management: "ml_predictive",    # ML-based memory prediction
    gpu_utilization: "dynamic_scaling",    # Adaptive GPU usage
    thread_optimization: "workload_aware", # Smart thread allocation
    power_management: "adaptive",          # Dynamic power scaling
    neural_engine: "optimized"            # Enhanced neural engine usage
}

## Model Configuration

model_preference: [
    "gpt-4o",                             # Primary for complex reasoning
    "cursor-small",                       # Fast edits and fixes
    "claude-3-sonnet-20240322",          # Specialized tasks
    "gemini-1.5-pro"                     # Auxiliary processing
]

## Token Optimization

token_management: {
    compression: {
        algorithm: "advanced_huffman",     # Enhanced compression
        context_aware: true,              # Smart context compression
        dynamic_adjustment: true          # Adaptive compression rates
    },
    caching: {
        strategy: "multi_level",          # Hierarchical caching
        prediction: "ml_based",           # ML-driven cache prefetch
        invalidation: "smart"             # Intelligent cache clearing
    },
    context: {
        max_size: 16000,                 # Maximum context window
        response_limit: 4000,            # Response size limit
        pruning: "intelligent"           # Smart context reduction
    }
}

## Cost Optimization

cost_control: {
    model_selection: {
        strategy: "cost_aware",           # Cost-based model routing
        fallback_chain: true,            # Smart model fallback
        performance_threshold: "adaptive" # Dynamic performance limits
    },
    token_efficiency: {
        compression_ratio: "maximum",     # Aggressive compression
        context_pruning: "intelligent",   # Smart context reduction
        response_optimization: "minimal"  # Minimal token responses
    },
    batching: {
        request_aggregation: true,        # Smart request batching
        priority_queuing: true,          # Priority-based processing
        dynamic_batch_size: true         # Adaptive batch sizing
    }
}

## Performance Monitoring

metrics_collection: {
    token_usage: {
        tracking: "per_request",          # Per-request token tracking
        analysis: "real_time",           # Real-time usage analysis
        optimization: "continuous"        # Continuous optimization
    },
    performance: {
        metrics: "detailed",             # Detailed performance data
        latency: "measured",            # Response time tracking
        efficiency: "analyzed"          # Efficiency analysis
    },
    resource: {
        utilization: "monitored",        # Resource monitoring
        optimization: "ml_based",        # ML-based optimization
        scaling: "dynamic"              # Dynamic resource scaling
    }
}

## Enforcement Rules

enforcement: {
    strict_mode: true,                   # Enforce all optimizations
    validation_required: true,           # Mandatory validation
    metrics_threshold: {
        token_reduction: 0.35,           # 35% minimum reduction
        response_time: 0.25,            # 25% speed improvement
        cost_reduction: 0.40,           # 40% cost reduction
        resource_efficiency: 0.35       # 35% resource optimization
    }
}

## Version Control

version: "3.0.0"
last_updated: "2024-03-21"
next_review: "2024-04-21"
